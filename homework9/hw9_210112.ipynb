{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPHwoXIBeVTE/pwwHOT8vzs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lbuerger/IANNwTF/blob/main/homework9/hw9_210112.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxqVa276p9o0"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeFYuLwnqObk"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klDG-QR1r4D2"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wXiHdZGr56A"
      },
      "source": [
        "from tensorflow.keras import Model\r\n",
        "from tensorflow.keras import layers\r\n",
        "\r\n",
        "class LSTM_Cell(layers.Layer):\r\n",
        "  def __init__(self, unit_size):\r\n",
        "    super(LSTM_Cell, self).__init__()\r\n",
        "    self.forget_layer = layers.Dense(unit_size, activation=\"sigmoid\", bias_initializer=\"ones\")\r\n",
        "    self.input_layer = layers.Dense(unit_size, activation=\"sigmoid\")\r\n",
        "    self.candidate_layer = layers.Dense(unit_size,  activation=\"tanh\")\r\n",
        "    self.output_layer = layers.Dense(unit_size, activation=\"sigmoid\")\r\n",
        "  \r\n",
        "  def call(self, x, states):\r\n",
        "    hidden_state, cell_state = states\r\n",
        "    hidden_state = layers.concatenate([x, hidden_state])\r\n",
        "    forget_gate = self.forget_layer(hidden_state)\r\n",
        "    input_gate = self.input_layer(hidden_state)\r\n",
        "    cell_state_candidates = self.candidate_layer(hidden_state)\r\n",
        "    cell_state = cell_state * forget_gate + input_gate * cell_state_candidates\r\n",
        "    output_gate = self.output_layer(hidden_state)\r\n",
        "    hidden_state = output_gate * tf.math.tanh(cell_state)\r\n",
        "    return hidden_state, cell_state \r\n",
        "  \r\n",
        "class LSTM(layers.Layer):\r\n",
        "  def __init__(self, unit_size):\r\n",
        "    super(LSTM, self).__init__()\r\n",
        "    self.unit_size = unit_size\r\n",
        "    self.cell = LSTM_Cell(unit_size)\r\n",
        "\r\n",
        "  def call(self, x):\r\n",
        "    sequence_length = x.shape[1]\r\n",
        "    outputs = []\r\n",
        "    states = self.zero_states(x.shape[0])\r\n",
        "    for i in range(sequence_length):\r\n",
        "      states = self.cell(x[:,i,:],states)\r\n",
        "      outputs.append(states[0])\r\n",
        "    return tf.stack(outputs, axis=1)\r\n",
        "\r\n",
        "  def zero_states(self, batch_size):\r\n",
        "    state = tf.zeros((batch_size,self.unit_size))\r\n",
        "    return (state, state)\r\n",
        "\r\n",
        "class LSTM_Model(Model):\r\n",
        "  def __init__(self, unit_size):\r\n",
        "    super(LSTM_Model, self).__init__()\r\n",
        "    self.unit_size = unit_size\r\n",
        "    self.input_layer = layers.Dense(10, activation=\"sigmoid\")\r\n",
        "    self.lstm = LSTM(unit_size)\r\n",
        "    self.output_layer = layers.Dense(1,activation=\"sigmoid\")\r\n",
        "\r\n",
        "  def call(self, x):\r\n",
        "    x = self.input_layer(x)\r\n",
        "    x = self.lstm(x)\r\n",
        "    x = self.output_layer(x)\r\n",
        "    return x"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vT53oT5b1Ym2",
        "outputId": "66c2080f-4ce8-444e-c592-1753235d73f6"
      },
      "source": [
        "lstm = LSTM_Cell(unit_size=5)\r\n",
        "lstm(tf.ones((10,21)),(tf.ones((10,5)),tf.ones([10,5])))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(10, 5), dtype=float32, numpy=\n",
              " array([[0.04157071, 0.4824632 , 0.47581053, 0.02914214, 0.0556259 ],\n",
              "        [0.04157071, 0.4824632 , 0.47581053, 0.02914214, 0.0556259 ],\n",
              "        [0.04157071, 0.4824632 , 0.47581053, 0.02914214, 0.0556259 ],\n",
              "        [0.04157071, 0.4824632 , 0.47581053, 0.02914214, 0.0556259 ],\n",
              "        [0.04157071, 0.4824632 , 0.47581053, 0.02914214, 0.0556259 ],\n",
              "        [0.04157071, 0.4824632 , 0.47581053, 0.02914214, 0.0556259 ],\n",
              "        [0.04157071, 0.4824632 , 0.47581053, 0.02914214, 0.0556259 ],\n",
              "        [0.04157071, 0.4824632 , 0.47581053, 0.02914214, 0.0556259 ],\n",
              "        [0.04157071, 0.4824632 , 0.47581053, 0.02914214, 0.0556259 ],\n",
              "        [0.04157071, 0.4824632 , 0.47581053, 0.02914214, 0.0556259 ]],\n",
              "       dtype=float32)>, <tf.Tensor: shape=(10, 5), dtype=float32, numpy=\n",
              " array([[0.05412787, 1.2354453 , 0.6031881 , 0.79008186, 0.26872927],\n",
              "        [0.05412787, 1.2354453 , 0.6031881 , 0.79008186, 0.26872927],\n",
              "        [0.05412787, 1.2354453 , 0.6031881 , 0.79008186, 0.26872927],\n",
              "        [0.05412787, 1.2354453 , 0.6031881 , 0.79008186, 0.26872927],\n",
              "        [0.05412787, 1.2354453 , 0.6031881 , 0.79008186, 0.26872927],\n",
              "        [0.05412787, 1.2354453 , 0.6031881 , 0.79008186, 0.26872927],\n",
              "        [0.05412787, 1.2354453 , 0.6031881 , 0.79008186, 0.26872927],\n",
              "        [0.05412787, 1.2354453 , 0.6031881 , 0.79008186, 0.26872927],\n",
              "        [0.05412787, 1.2354453 , 0.6031881 , 0.79008186, 0.26872927],\n",
              "        [0.05412787, 1.2354453 , 0.6031881 , 0.79008186, 0.26872927]],\n",
              "       dtype=float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13T9mkT51sX_",
        "outputId": "34be8765-9934-492e-ded3-99c938ab9337"
      },
      "source": [
        "model = LSTM_Model(10)\r\n",
        "out = model(tf.ones((32,20,30)))\r\n",
        "print(out[:,-1,:].shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H564fqeZRS84"
      },
      "source": [
        "def train_step(model, input, target, loss_function, optimizer):\r\n",
        "  with tf.GradientTape() as tape:\r\n",
        "    prediction = model(input)[:,-1,:]\r\n",
        "    #print(prediction)\r\n",
        "    #print(target)\r\n",
        "    loss = loss_function(target, prediction)\r\n",
        "  optimizer.minimize(loss, model.trainable_variables, tape=tape)\r\n",
        "  acc = 1 - tf.reduce_mean(tf.math.abs(prediction-target))\r\n",
        "  return loss, acc "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ilqbi_ewXRgt",
        "outputId": "825ea483-27f8-48b2-9bf8-f8189d10436c"
      },
      "source": [
        "def target_in_row(row, context):\r\n",
        "  # 1 if context[0] more frequent than context[1] or equally often\r\n",
        "  #print(context)\r\n",
        "  sum1 = tf.reduce_sum(tf.cast(tf.math.equal(row,context[0]), tf.int32))\r\n",
        "  sum2 = tf.reduce_sum(tf.cast(tf.math.equal(row,context[1]), tf.int32))\r\n",
        "  return tf.constant([0.0]) if sum2>sum1 else tf.constant([1.0])\r\n",
        "\r\n",
        "def calc_targets(input, context):\r\n",
        "  targets = []\r\n",
        "  for row,cont in zip(input,context):\r\n",
        "    #print(\"row\",row, cont)\r\n",
        "    targets.append(target_in_row(row,cont))\r\n",
        "  return tf.stack(targets)\r\n",
        "\r\n",
        "def create_sequence(batch_size,sequence_length):\r\n",
        "  randoms = tf.experimental.numpy.random.randint(0,10,size=(batch_size,sequence_length))\r\n",
        "  context = tf.experimental.numpy.random.randint(0,10,size=(batch_size, 2))\r\n",
        "  #tf.one_hot(randoms,10)\r\n",
        "  return randoms, context\r\n",
        "\r\n",
        "def build_input(sequence,context):\r\n",
        "  seq_shape = sequence.shape\r\n",
        "  context = tf.one_hot(context,10)\r\n",
        "  context = tf.reshape(context, (seq_shape[0],20))\r\n",
        "  #print(context)\r\n",
        "  timesteps = []\r\n",
        "  for i in range(seq_shape[1]):\r\n",
        "    step = tf.one_hot(sequence[:,i],10)\r\n",
        "    concat = tf.concat([context,step],1)\r\n",
        "    #print(concat)\r\n",
        "    timesteps.append(concat)\r\n",
        "  return tf.stack(timesteps, axis=1)\r\n",
        "\r\n",
        "def get_input_target(batch_size, sequence_length):\r\n",
        "  sequence, context = create_sequence(batch_size, sequence_length)\r\n",
        "  target = calc_targets(sequence, context)\r\n",
        "  input = build_input(sequence, context)\r\n",
        "  return input, target\r\n",
        "\r\n",
        "seq, cont = create_sequence(3,20)\r\n",
        "print(seq)\r\n",
        "print(cont)\r\n",
        "tmp = calc_targets(seq,cont)\r\n",
        "#calc_targets()\r\n",
        "print(\"targets\",tmp.shape)\r\n",
        "build_input(seq, cont).shape\r\n",
        "\r\n",
        "inp, targ = get_input_target(32,20)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ndarray<tf.Tensor(\n",
            "[[0 0 2 8 5 8 0 3 9 5 6 8 1 9 8 8 8 8 5 8]\n",
            " [4 8 6 1 9 7 5 7 0 3 8 1 7 6 6 9 3 0 7 6]\n",
            " [2 8 7 7 4 8 4 5 1 4 4 3 0 0 1 3 4 6 7 9]], shape=(3, 20), dtype=int64)>\n",
            "ndarray<tf.Tensor(\n",
            "[[1 0]\n",
            " [4 2]\n",
            " [5 6]], shape=(3, 2), dtype=int64)>\n",
            "targets (3, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSN96RxAUdxh",
        "outputId": "72095644-58ec-43dc-fdf0-59f66bbd6841"
      },
      "source": [
        "tf.keras.backend.clear_session()\r\n",
        "\r\n",
        "num_epochs = 40\r\n",
        "num_steps_per_epoch = 1000\r\n",
        "learning_rate = 0.001\r\n",
        "running_average_factor = 0.95\r\n",
        "\r\n",
        "unit_size = 20\r\n",
        "batch_size = 32\r\n",
        "sequence_length = 20\r\n",
        "model = LSTM_Model(unit_size=unit_size)\r\n",
        "# Using binary correntropy due to values between 0 and 1\r\n",
        "loss_function = tf.keras.losses.BinaryCrossentropy()\r\n",
        "# Using the Adam optimizer with the defined learnig rate\r\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate) #,amsgrad=True)\r\n",
        "\r\n",
        "train_losses = []\r\n",
        "train_acc = []\r\n",
        "model(get_input_target(batch_size, sequence_length)[0])\r\n",
        "print(model.summary())\r\n",
        "\r\n",
        "time0 = time.time()\r\n",
        "\r\n",
        "for epoch in range(num_epochs):\r\n",
        "  print(\"Epoch:\", epoch, \"/\", num_epochs)\r\n",
        "  running_avg_loss = 0\r\n",
        "  running_avg_acc = 0\r\n",
        "\r\n",
        "  for step in range(num_steps_per_epoch):\r\n",
        "    input, target = get_input_target(batch_size, sequence_length)\r\n",
        "    loss, acc = train_step(model, input, target, loss_function, optimizer)\r\n",
        "    running_avg_loss = running_average_factor * running_avg_loss + (1 - running_average_factor) * loss\r\n",
        "    running_avg_acc = running_average_factor * running_avg_acc + (1 - running_average_factor) * acc\r\n",
        "  train_losses.append(running_avg_loss)\r\n",
        "  train_acc.append(running_avg_acc)\r\n",
        "\r\n",
        "  run_time = time.time()-time0 \r\n",
        "  print(\"After Epoch\",epoch,'train_loss:', round(running_avg_loss.numpy(),4),'train_acc:', round(running_avg_acc.numpy(),4), \"running:\",round(run_time,1),\"sec ETA:\",round(((run_time)/(epoch+1)*num_epochs-run_time)/60,1),\"min\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"lstm__model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                multiple                  310       \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  multiple                  2480      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              multiple                  21        \n",
            "=================================================================\n",
            "Total params: 2,811\n",
            "Trainable params: 2,811\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch: 0 / 40\n",
            "After Epoch 0 train_loss: 0.6507 train_acc: 0.5393 running: 127.8 sec ETA: 83.0 min\n",
            "Epoch: 1 / 40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_y7xWL5VSHP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}