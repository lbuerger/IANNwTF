{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOO4Gn0+VFou1x0o1ybEO7q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lbuerger/IANNwTF/blob/main/homework9/hw9_210112.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxqVa276p9o0"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import time"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeFYuLwnqObk"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klDG-QR1r4D2"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wXiHdZGr56A"
      },
      "source": [
        "from tensorflow.keras import Model\r\n",
        "from tensorflow.keras import layers\r\n",
        "\r\n",
        "class LSTM_Cell(layers.Layer):\r\n",
        "  def __init__(self, unit_size):\r\n",
        "    super(LSTM_Cell, self).__init__()\r\n",
        "    self.forget_layer = layers.Dense(unit_size, activation=\"sigmoid\", bias_initializer=\"ones\")\r\n",
        "    self.input_layer = layers.Dense(unit_size, activation=\"sigmoid\")\r\n",
        "    self.candidate_layer = layers.Dense(unit_size,  activation=\"tanh\")\r\n",
        "    self.output_layer = layers.Dense(unit_size, activation=\"sigmoid\")\r\n",
        "  \r\n",
        "  def call(self, x, states):\r\n",
        "    hidden_state, cell_state = states\r\n",
        "    hidden_state = layers.concatenate([x, hidden_state])\r\n",
        "    forget_gate = self.forget_layer(hidden_state)\r\n",
        "    input_gate = self.input_layer(hidden_state)\r\n",
        "    cell_state_candidates = self.candidate_layer(hidden_state)\r\n",
        "    cell_state = cell_state * forget_gate + input_gate * cell_state_candidates\r\n",
        "    output_gate = self.output_layer(hidden_state)\r\n",
        "    hidden_state = output_gate * tf.math.tanh(cell_state)\r\n",
        "    return hidden_state, cell_state \r\n",
        "  \r\n",
        "class LSTM(layers.Layer):\r\n",
        "  def __init__(self, unit_size):\r\n",
        "    super(LSTM, self).__init__()\r\n",
        "    self.unit_size = unit_size\r\n",
        "    self.cell = LSTM_Cell(unit_size)\r\n",
        "\r\n",
        "  def call(self, x):\r\n",
        "    sequence_length = x.shape[1]\r\n",
        "    outputs = []\r\n",
        "    states = self.zero_states(x.shape[0])\r\n",
        "    for i in range(sequence_length):\r\n",
        "      states = self.cell(x[:,i,:],states)\r\n",
        "      outputs.append(states[0])\r\n",
        "    return tf.stack(outputs, axis=1)\r\n",
        "\r\n",
        "  def zero_states(self, batch_size):\r\n",
        "    state = tf.zeros((batch_size,self.unit_size))\r\n",
        "    return (state, state)\r\n",
        "\r\n",
        "class LSTM_Model(Model):\r\n",
        "  def __init__(self, unit_size):\r\n",
        "    super(LSTM_Model, self).__init__()\r\n",
        "    self.unit_size = unit_size\r\n",
        "    self.input_layer = layers.Dense(10, activation=\"sigmoid\")\r\n",
        "    self.lstm = LSTM(unit_size)\r\n",
        "    self.output_layer = layers.Dense(1,activation=\"sigmoid\")\r\n",
        "\r\n",
        "  def call(self, x):\r\n",
        "    x = self.input_layer(x)\r\n",
        "    x = self.lstm(x)\r\n",
        "    x = self.output_layer(x)\r\n",
        "    return x"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vT53oT5b1Ym2",
        "outputId": "bdafc951-a07d-4b66-fd5b-9fcecf5bfbfe"
      },
      "source": [
        "lstm = LSTM_Cell(unit_size=5)\r\n",
        "lstm(tf.ones((10,21)),(tf.ones((10,5)),tf.ones([10,5])))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(10, 5), dtype=float32, numpy=\n",
              " array([[0.26082015, 0.3606508 , 0.24511595, 0.15747857, 0.1966048 ],\n",
              "        [0.26082015, 0.3606508 , 0.24511595, 0.15747857, 0.1966048 ],\n",
              "        [0.26082015, 0.3606508 , 0.24511595, 0.15747857, 0.1966048 ],\n",
              "        [0.26082015, 0.3606508 , 0.24511595, 0.15747857, 0.1966048 ],\n",
              "        [0.26082015, 0.3606508 , 0.24511595, 0.15747857, 0.1966048 ],\n",
              "        [0.26082015, 0.3606508 , 0.24511595, 0.15747857, 0.1966048 ],\n",
              "        [0.26082015, 0.3606508 , 0.24511595, 0.15747857, 0.1966048 ],\n",
              "        [0.26082015, 0.3606508 , 0.24511595, 0.15747857, 0.1966048 ],\n",
              "        [0.26082015, 0.3606508 , 0.24511595, 0.15747857, 0.1966048 ],\n",
              "        [0.26082015, 0.3606508 , 0.24511595, 0.15747857, 0.1966048 ]],\n",
              "       dtype=float32)>, <tf.Tensor: shape=(10, 5), dtype=float32, numpy=\n",
              " array([[1.1433828, 0.7421621, 0.8509246, 1.0303158, 0.8188895],\n",
              "        [1.1433828, 0.7421621, 0.8509246, 1.0303158, 0.8188895],\n",
              "        [1.1433828, 0.7421621, 0.8509246, 1.0303158, 0.8188895],\n",
              "        [1.1433828, 0.7421621, 0.8509246, 1.0303158, 0.8188895],\n",
              "        [1.1433828, 0.7421621, 0.8509246, 1.0303158, 0.8188895],\n",
              "        [1.1433828, 0.7421621, 0.8509246, 1.0303158, 0.8188895],\n",
              "        [1.1433828, 0.7421621, 0.8509246, 1.0303158, 0.8188895],\n",
              "        [1.1433828, 0.7421621, 0.8509246, 1.0303158, 0.8188895],\n",
              "        [1.1433828, 0.7421621, 0.8509246, 1.0303158, 0.8188895],\n",
              "        [1.1433828, 0.7421621, 0.8509246, 1.0303158, 0.8188895]],\n",
              "       dtype=float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13T9mkT51sX_",
        "outputId": "faeebccb-9b63-43dc-971d-63b659d22730"
      },
      "source": [
        "model = LSTM_Model(10)\r\n",
        "out = model(tf.ones((32,20,30)))\r\n",
        "print(out[:,-1,:].shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H564fqeZRS84"
      },
      "source": [
        "def train_step(model, input, target, loss_function, optimizer):\r\n",
        "  with tf.GradientTape() as tape:\r\n",
        "    prediction = model(input)[:,-1,:]\r\n",
        "    #print(prediction)\r\n",
        "    #print(target)\r\n",
        "    loss = loss_function(target, prediction)\r\n",
        "  optimizer.minimize(loss, model.trainable_variables, tape=tape)\r\n",
        "  acc = 1 - tf.reduce_mean(tf.math.abs(prediction-target))\r\n",
        "  return loss, acc "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ilqbi_ewXRgt",
        "outputId": "647817fd-50b5-43a1-99be-111517477f81"
      },
      "source": [
        "def target_in_row(row, context):\r\n",
        "  # 1 if context[0] more frequent than context[1] or equally often\r\n",
        "  #print(context)\r\n",
        "  sum1 = tf.reduce_sum(tf.cast(tf.math.equal(row,context[0]), tf.int32))\r\n",
        "  sum2 = tf.reduce_sum(tf.cast(tf.math.equal(row,context[1]), tf.int32))\r\n",
        "  return tf.constant([0.0]) if sum2>sum1 else tf.constant([1.0])\r\n",
        "\r\n",
        "def calc_targets(input, context):\r\n",
        "  targets = []\r\n",
        "  for row,cont in zip(input,context):\r\n",
        "    #print(\"row\",row, cont)\r\n",
        "    targets.append(target_in_row(row,cont))\r\n",
        "  return tf.stack(targets)\r\n",
        "\r\n",
        "def create_sequence(batch_size,sequence_length):\r\n",
        "  randoms = tf.experimental.numpy.random.randint(0,10,size=(batch_size,sequence_length))\r\n",
        "  context = tf.experimental.numpy.random.randint(0,10,size=(batch_size, 2))\r\n",
        "  #tf.one_hot(randoms,10)\r\n",
        "  return randoms, context\r\n",
        "\r\n",
        "def build_input(sequence,context):\r\n",
        "  seq_shape = sequence.shape\r\n",
        "  context = tf.one_hot(context,10)\r\n",
        "  context = tf.reshape(context, (seq_shape[0],20))\r\n",
        "  #print(context)\r\n",
        "  timesteps = []\r\n",
        "  for i in range(seq_shape[1]):\r\n",
        "    step = tf.one_hot(sequence[:,i],10)\r\n",
        "    concat = tf.concat([context,step],1)\r\n",
        "    #print(concat)\r\n",
        "    timesteps.append(concat)\r\n",
        "  return tf.stack(timesteps, axis=1)\r\n",
        "\r\n",
        "def get_input_target(batch_size, sequence_length):\r\n",
        "  sequence, context = create_sequence(batch_size, sequence_length)\r\n",
        "  target = calc_targets(sequence, context)\r\n",
        "  input = build_input(sequence, context)\r\n",
        "  return input, target\r\n",
        "\r\n",
        "seq, cont = create_sequence(3,20)\r\n",
        "print(seq)\r\n",
        "print(cont)\r\n",
        "tmp = calc_targets(seq,cont)\r\n",
        "#calc_targets()\r\n",
        "print(\"targets\",tmp.shape)\r\n",
        "build_input(seq, cont).shape\r\n",
        "\r\n",
        "inp, targ = get_input_target(32,20)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ndarray<tf.Tensor(\n",
            "[[2 9 5 2 6 9 1 8 6 1 0 6 2 4 3 4 4 1 9 9]\n",
            " [0 6 5 3 5 2 5 2 9 3 4 7 6 2 3 3 1 5 7 7]\n",
            " [6 7 5 5 8 4 9 6 3 6 7 7 6 4 1 5 0 8 5 7]], shape=(3, 20), dtype=int64)>\n",
            "ndarray<tf.Tensor(\n",
            "[[8 9]\n",
            " [5 4]\n",
            " [2 3]], shape=(3, 2), dtype=int64)>\n",
            "targets (3, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSN96RxAUdxh",
        "outputId": "3dac16db-ae9d-474b-c02a-67c5c968487f"
      },
      "source": [
        "tf.keras.backend.clear_session()\r\n",
        "\r\n",
        "num_epochs = 100\r\n",
        "num_steps_per_epoch = 1000\r\n",
        "learning_rate = 0.001\r\n",
        "running_average_factor = 0.95\r\n",
        "\r\n",
        "unit_size = 5\r\n",
        "batch_size = 32\r\n",
        "sequence_length = 10\r\n",
        "model = LSTM_Model(unit_size=unit_size)\r\n",
        "# Using binary correntropy due to values between 0 and 1\r\n",
        "loss_function = tf.keras.losses.BinaryCrossentropy()\r\n",
        "# Using the Adam optimizer with the defined learnig rate\r\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate) #,amsgrad=True)\r\n",
        "\r\n",
        "train_losses = []\r\n",
        "train_acc = []\r\n",
        "model(get_input_target(batch_size, sequence_length)[0])\r\n",
        "print(model.summary())\r\n",
        "\r\n",
        "time0 = time.time()\r\n",
        "\r\n",
        "for epoch in range(num_epochs):\r\n",
        "  print(\"Epoch:\", epoch, \"/\", num_epochs)\r\n",
        "  running_avg_loss = 0\r\n",
        "  running_avg_acc = 0\r\n",
        "\r\n",
        "  for step in range(num_steps_per_epoch):\r\n",
        "    input, target = get_input_target(batch_size, sequence_length)\r\n",
        "    loss, acc = train_step(model, input, target, loss_function, optimizer)\r\n",
        "    running_avg_loss = running_average_factor * running_avg_loss + (1 - running_average_factor) * loss\r\n",
        "    running_avg_acc = running_average_factor * running_avg_acc + (1 - running_average_factor) * acc\r\n",
        "  train_losses.append(running_avg_loss)\r\n",
        "  train_acc.append(running_avg_acc)\r\n",
        "\r\n",
        "  run_time = time.time()-time0 \r\n",
        "  print(\"After Epoch\",epoch,'train_loss:', round(running_avg_loss.numpy(),4),'train_acc:', round(running_avg_acc.numpy(),4), \"running:\",round(run_time,1),\"sec ETA:\",round(((run_time)/(epoch+1)*num_epochs-run_time)/60,1),\"min\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"lstm__model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                multiple                  310       \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  multiple                  320       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              multiple                  6         \n",
            "=================================================================\n",
            "Total params: 636\n",
            "Trainable params: 636\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch: 0 / 100\n",
            "After Epoch 0 train_loss: 0.6272 train_acc: 0.5674 running: 77.8 sec ETA: 128.3 min\n",
            "Epoch: 1 / 100\n",
            "After Epoch 1 train_loss: 0.5971 train_acc: 0.5839 running: 155.5 sec ETA: 127.0 min\n",
            "Epoch: 2 / 100\n",
            "After Epoch 2 train_loss: 0.6136 train_acc: 0.5747 running: 232.6 sec ETA: 125.3 min\n",
            "Epoch: 3 / 100\n",
            "After Epoch 3 train_loss: 0.6296 train_acc: 0.5637 running: 309.9 sec ETA: 124.0 min\n",
            "Epoch: 4 / 100\n",
            "After Epoch 4 train_loss: 0.6101 train_acc: 0.5813 running: 387.3 sec ETA: 122.6 min\n",
            "Epoch: 5 / 100\n",
            "After Epoch 5 train_loss: 0.6071 train_acc: 0.5831 running: 464.4 sec ETA: 121.3 min\n",
            "Epoch: 6 / 100\n",
            "After Epoch 6 train_loss: 0.606 train_acc: 0.582 running: 541.8 sec ETA: 120.0 min\n",
            "Epoch: 7 / 100\n",
            "After Epoch 7 train_loss: 0.6012 train_acc: 0.591 running: 618.3 sec ETA: 118.5 min\n",
            "Epoch: 8 / 100\n",
            "After Epoch 8 train_loss: 0.5839 train_acc: 0.5957 running: 695.5 sec ETA: 117.2 min\n",
            "Epoch: 9 / 100\n",
            "After Epoch 9 train_loss: 0.5875 train_acc: 0.6006 running: 772.0 sec ETA: 115.8 min\n",
            "Epoch: 10 / 100\n",
            "After Epoch 10 train_loss: 0.5873 train_acc: 0.6003 running: 848.7 sec ETA: 114.4 min\n",
            "Epoch: 11 / 100\n",
            "After Epoch 11 train_loss: 0.5917 train_acc: 0.5927 running: 926.4 sec ETA: 113.2 min\n",
            "Epoch: 12 / 100\n",
            "After Epoch 12 train_loss: 0.5725 train_acc: 0.6081 running: 1004.1 sec ETA: 112.0 min\n",
            "Epoch: 13 / 100\n",
            "After Epoch 13 train_loss: 0.6086 train_acc: 0.5763 running: 1080.9 sec ETA: 110.7 min\n",
            "Epoch: 14 / 100\n",
            "After Epoch 14 train_loss: 0.5853 train_acc: 0.6019 running: 1157.8 sec ETA: 109.3 min\n",
            "Epoch: 15 / 100\n",
            "After Epoch 15 train_loss: 0.6019 train_acc: 0.5937 running: 1235.2 sec ETA: 108.1 min\n",
            "Epoch: 16 / 100\n",
            "After Epoch 16 train_loss: 0.5907 train_acc: 0.5886 running: 1312.3 sec ETA: 106.8 min\n",
            "Epoch: 17 / 100\n",
            "After Epoch 17 train_loss: 0.5935 train_acc: 0.5935 running: 1389.0 sec ETA: 105.5 min\n",
            "Epoch: 18 / 100\n",
            "After Epoch 18 train_loss: 0.5918 train_acc: 0.593 running: 1466.0 sec ETA: 104.2 min\n",
            "Epoch: 19 / 100\n",
            "After Epoch 19 train_loss: 0.5782 train_acc: 0.601 running: 1543.0 sec ETA: 102.9 min\n",
            "Epoch: 20 / 100\n",
            "After Epoch 20 train_loss: 0.5545 train_acc: 0.6172 running: 1619.7 sec ETA: 101.6 min\n",
            "Epoch: 21 / 100\n",
            "After Epoch 21 train_loss: 0.585 train_acc: 0.5983 running: 1697.5 sec ETA: 100.3 min\n",
            "Epoch: 22 / 100\n",
            "After Epoch 22 train_loss: 0.5552 train_acc: 0.6178 running: 1775.2 sec ETA: 99.1 min\n",
            "Epoch: 23 / 100\n",
            "After Epoch 23 train_loss: 0.5713 train_acc: 0.6196 running: 1852.4 sec ETA: 97.8 min\n",
            "Epoch: 24 / 100\n",
            "After Epoch 24 train_loss: 0.5373 train_acc: 0.6367 running: 1929.7 sec ETA: 96.5 min\n",
            "Epoch: 25 / 100\n",
            "After Epoch 25 train_loss: 0.5166 train_acc: 0.6532 running: 2006.6 sec ETA: 95.2 min\n",
            "Epoch: 26 / 100\n",
            "After Epoch 26 train_loss: 0.4961 train_acc: 0.6597 running: 2084.1 sec ETA: 93.9 min\n",
            "Epoch: 27 / 100\n",
            "After Epoch 27 train_loss: 0.501 train_acc: 0.6547 running: 2161.6 sec ETA: 92.6 min\n",
            "Epoch: 28 / 100\n",
            "After Epoch 28 train_loss: 0.4983 train_acc: 0.6697 running: 2239.4 sec ETA: 91.4 min\n",
            "Epoch: 29 / 100\n",
            "After Epoch 29 train_loss: 0.4722 train_acc: 0.6815 running: 2316.3 sec ETA: 90.1 min\n",
            "Epoch: 30 / 100\n",
            "After Epoch 30 train_loss: 0.4605 train_acc: 0.6888 running: 2393.6 sec ETA: 88.8 min\n",
            "Epoch: 31 / 100\n",
            "After Epoch 31 train_loss: 0.4552 train_acc: 0.6933 running: 2471.2 sec ETA: 87.5 min\n",
            "Epoch: 32 / 100\n",
            "After Epoch 32 train_loss: 0.4429 train_acc: 0.7128 running: 2547.8 sec ETA: 86.2 min\n",
            "Epoch: 33 / 100\n",
            "After Epoch 33 train_loss: 0.4164 train_acc: 0.7204 running: 2624.6 sec ETA: 84.9 min\n",
            "Epoch: 34 / 100\n",
            "After Epoch 34 train_loss: 0.4116 train_acc: 0.7306 running: 2701.8 sec ETA: 83.6 min\n",
            "Epoch: 35 / 100\n",
            "After Epoch 35 train_loss: 0.3898 train_acc: 0.7384 running: 2778.7 sec ETA: 82.3 min\n",
            "Epoch: 36 / 100\n",
            "After Epoch 36 train_loss: 0.3846 train_acc: 0.7412 running: 2855.5 sec ETA: 81.0 min\n",
            "Epoch: 37 / 100\n",
            "After Epoch 37 train_loss: 0.3986 train_acc: 0.7417 running: 2932.7 sec ETA: 79.7 min\n",
            "Epoch: 38 / 100\n",
            "After Epoch 38 train_loss: 0.3502 train_acc: 0.7653 running: 3009.6 sec ETA: 78.5 min\n",
            "Epoch: 39 / 100\n",
            "After Epoch 39 train_loss: 0.3502 train_acc: 0.7674 running: 3086.7 sec ETA: 77.2 min\n",
            "Epoch: 40 / 100\n",
            "After Epoch 40 train_loss: 0.3556 train_acc: 0.764 running: 3163.6 sec ETA: 75.9 min\n",
            "Epoch: 41 / 100\n",
            "After Epoch 41 train_loss: 0.3311 train_acc: 0.7775 running: 3241.0 sec ETA: 74.6 min\n",
            "Epoch: 42 / 100\n",
            "After Epoch 42 train_loss: 0.3716 train_acc: 0.7619 running: 3317.8 sec ETA: 73.3 min\n",
            "Epoch: 43 / 100\n",
            "After Epoch 43 train_loss: 0.3128 train_acc: 0.7913 running: 3394.5 sec ETA: 72.0 min\n",
            "Epoch: 44 / 100\n",
            "After Epoch 44 train_loss: 0.3456 train_acc: 0.7774 running: 3471.6 sec ETA: 70.7 min\n",
            "Epoch: 45 / 100\n",
            "After Epoch 45 train_loss: 0.3352 train_acc: 0.7888 running: 3549.0 sec ETA: 69.4 min\n",
            "Epoch: 46 / 100\n",
            "After Epoch 46 train_loss: 0.3233 train_acc: 0.7908 running: 3626.3 sec ETA: 68.2 min\n",
            "Epoch: 47 / 100\n",
            "After Epoch 47 train_loss: 0.3228 train_acc: 0.7862 running: 3703.7 sec ETA: 66.9 min\n",
            "Epoch: 48 / 100\n",
            "After Epoch 48 train_loss: 0.3018 train_acc: 0.8043 running: 3781.1 sec ETA: 65.6 min\n",
            "Epoch: 49 / 100\n",
            "After Epoch 49 train_loss: 0.3048 train_acc: 0.7991 running: 3857.9 sec ETA: 64.3 min\n",
            "Epoch: 50 / 100\n",
            "After Epoch 50 train_loss: 0.2895 train_acc: 0.8084 running: 3935.2 sec ETA: 63.0 min\n",
            "Epoch: 51 / 100\n",
            "After Epoch 51 train_loss: 0.3169 train_acc: 0.8018 running: 4012.0 sec ETA: 61.7 min\n",
            "Epoch: 52 / 100\n",
            "After Epoch 52 train_loss: 0.2832 train_acc: 0.8148 running: 4089.6 sec ETA: 60.4 min\n",
            "Epoch: 53 / 100\n",
            "After Epoch 53 train_loss: 0.3313 train_acc: 0.791 running: 4167.0 sec ETA: 59.2 min\n",
            "Epoch: 54 / 100\n",
            "After Epoch 54 train_loss: 0.2907 train_acc: 0.8124 running: 4244.5 sec ETA: 57.9 min\n",
            "Epoch: 55 / 100\n",
            "After Epoch 55 train_loss: 0.295 train_acc: 0.8048 running: 4322.1 sec ETA: 56.6 min\n",
            "Epoch: 56 / 100\n",
            "After Epoch 56 train_loss: 0.282 train_acc: 0.8209 running: 4399.3 sec ETA: 55.3 min\n",
            "Epoch: 57 / 100\n",
            "After Epoch 57 train_loss: 0.2851 train_acc: 0.8176 running: 4476.6 sec ETA: 54.0 min\n",
            "Epoch: 58 / 100\n",
            "After Epoch 58 train_loss: 0.2766 train_acc: 0.8204 running: 4554.5 sec ETA: 52.8 min\n",
            "Epoch: 59 / 100\n",
            "After Epoch 59 train_loss: 0.2587 train_acc: 0.8318 running: 4632.4 sec ETA: 51.5 min\n",
            "Epoch: 60 / 100\n",
            "After Epoch 60 train_loss: 0.2673 train_acc: 0.8282 running: 4710.1 sec ETA: 50.2 min\n",
            "Epoch: 61 / 100\n",
            "After Epoch 61 train_loss: 0.2671 train_acc: 0.8272 running: 4787.6 sec ETA: 48.9 min\n",
            "Epoch: 62 / 100\n",
            "After Epoch 62 train_loss: 0.2628 train_acc: 0.8318 running: 4864.9 sec ETA: 47.6 min\n",
            "Epoch: 63 / 100\n",
            "After Epoch 63 train_loss: 0.2433 train_acc: 0.8417 running: 4942.5 sec ETA: 46.3 min\n",
            "Epoch: 64 / 100\n",
            "After Epoch 64 train_loss: 0.2562 train_acc: 0.835 running: 5019.9 sec ETA: 45.1 min\n",
            "Epoch: 65 / 100\n",
            "After Epoch 65 train_loss: 0.24 train_acc: 0.8457 running: 5097.8 sec ETA: 43.8 min\n",
            "Epoch: 66 / 100\n",
            "After Epoch 66 train_loss: 0.2432 train_acc: 0.8476 running: 5175.1 sec ETA: 42.5 min\n",
            "Epoch: 67 / 100\n",
            "After Epoch 67 train_loss: 0.2369 train_acc: 0.8451 running: 5252.2 sec ETA: 41.2 min\n",
            "Epoch: 68 / 100\n",
            "After Epoch 68 train_loss: 0.2391 train_acc: 0.8494 running: 5329.6 sec ETA: 39.9 min\n",
            "Epoch: 69 / 100\n",
            "After Epoch 69 train_loss: 0.2392 train_acc: 0.8502 running: 5407.1 sec ETA: 38.6 min\n",
            "Epoch: 70 / 100\n",
            "After Epoch 70 train_loss: 0.24 train_acc: 0.8463 running: 5484.4 sec ETA: 37.3 min\n",
            "Epoch: 71 / 100\n",
            "After Epoch 71 train_loss: 0.2564 train_acc: 0.8407 running: 5561.7 sec ETA: 36.0 min\n",
            "Epoch: 72 / 100\n",
            "After Epoch 72 train_loss: 0.2014 train_acc: 0.8653 running: 5639.5 sec ETA: 34.8 min\n",
            "Epoch: 73 / 100\n",
            "After Epoch 73 train_loss: 0.2055 train_acc: 0.863 running: 5717.0 sec ETA: 33.5 min\n",
            "Epoch: 74 / 100\n",
            "After Epoch 74 train_loss: 0.2144 train_acc: 0.8601 running: 5794.3 sec ETA: 32.2 min\n",
            "Epoch: 75 / 100\n",
            "After Epoch 75 train_loss: 0.2282 train_acc: 0.8553 running: 5871.7 sec ETA: 30.9 min\n",
            "Epoch: 76 / 100\n",
            "After Epoch 76 train_loss: 0.2415 train_acc: 0.8503 running: 5949.7 sec ETA: 29.6 min\n",
            "Epoch: 77 / 100\n",
            "After Epoch 77 train_loss: 0.2089 train_acc: 0.8643 running: 6027.3 sec ETA: 28.3 min\n",
            "Epoch: 78 / 100\n",
            "After Epoch 78 train_loss: 0.2256 train_acc: 0.86 running: 6105.0 sec ETA: 27.0 min\n",
            "Epoch: 79 / 100\n",
            "After Epoch 79 train_loss: 0.2313 train_acc: 0.8587 running: 6182.0 sec ETA: 25.8 min\n",
            "Epoch: 80 / 100\n",
            "After Epoch 80 train_loss: 0.2202 train_acc: 0.8598 running: 6259.3 sec ETA: 24.5 min\n",
            "Epoch: 81 / 100\n",
            "After Epoch 81 train_loss: 0.2228 train_acc: 0.8568 running: 6336.1 sec ETA: 23.2 min\n",
            "Epoch: 82 / 100\n",
            "After Epoch 82 train_loss: 0.2207 train_acc: 0.8615 running: 6413.1 sec ETA: 21.9 min\n",
            "Epoch: 83 / 100\n",
            "After Epoch 83 train_loss: 0.1967 train_acc: 0.8735 running: 6490.0 sec ETA: 20.6 min\n",
            "Epoch: 84 / 100\n",
            "After Epoch 84 train_loss: 0.232 train_acc: 0.8595 running: 6566.9 sec ETA: 19.3 min\n",
            "Epoch: 85 / 100\n",
            "After Epoch 85 train_loss: 0.1947 train_acc: 0.8769 running: 6643.7 sec ETA: 18.0 min\n",
            "Epoch: 86 / 100\n",
            "After Epoch 86 train_loss: 0.2142 train_acc: 0.8645 running: 6720.8 sec ETA: 16.7 min\n",
            "Epoch: 87 / 100\n",
            "After Epoch 87 train_loss: 0.1853 train_acc: 0.8825 running: 6797.8 sec ETA: 15.4 min\n",
            "Epoch: 88 / 100\n",
            "After Epoch 88 train_loss: 0.1743 train_acc: 0.887 running: 6874.6 sec ETA: 14.2 min\n",
            "Epoch: 89 / 100\n",
            "After Epoch 89 train_loss: 0.2005 train_acc: 0.8769 running: 6951.9 sec ETA: 12.9 min\n",
            "Epoch: 90 / 100\n",
            "After Epoch 90 train_loss: 0.2184 train_acc: 0.8697 running: 7028.9 sec ETA: 11.6 min\n",
            "Epoch: 91 / 100\n",
            "After Epoch 91 train_loss: 0.1812 train_acc: 0.8839 running: 7106.3 sec ETA: 10.3 min\n",
            "Epoch: 92 / 100\n",
            "After Epoch 92 train_loss: 0.2086 train_acc: 0.8739 running: 7183.6 sec ETA: 9.0 min\n",
            "Epoch: 93 / 100\n",
            "After Epoch 93 train_loss: 0.1806 train_acc: 0.8839 running: 7260.8 sec ETA: 7.7 min\n",
            "Epoch: 94 / 100\n",
            "After Epoch 94 train_loss: 0.178 train_acc: 0.8857 running: 7337.8 sec ETA: 6.4 min\n",
            "Epoch: 95 / 100\n",
            "After Epoch 95 train_loss: 0.1709 train_acc: 0.8873 running: 7415.4 sec ETA: 5.1 min\n",
            "Epoch: 96 / 100\n",
            "After Epoch 96 train_loss: 0.1729 train_acc: 0.8911 running: 7492.7 sec ETA: 3.9 min\n",
            "Epoch: 97 / 100\n",
            "After Epoch 97 train_loss: 0.1596 train_acc: 0.8959 running: 7570.9 sec ETA: 2.6 min\n",
            "Epoch: 98 / 100\n",
            "After Epoch 98 train_loss: 0.1506 train_acc: 0.8968 running: 7649.0 sec ETA: 1.3 min\n",
            "Epoch: 99 / 100\n",
            "After Epoch 99 train_loss: 0.1876 train_acc: 0.8874 running: 7726.3 sec ETA: 0.0 min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "L_y7xWL5VSHP",
        "outputId": "5303e874-7275-4ac6-b6e0-962c6e703f77"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "plt.figure()\r\n",
        "plt.plot(train_losses, label=\"losses\")\r\n",
        "plt.plot(train_acc, label=\"accuracy\")\r\n",
        "plt.xlabel(\"Training steps\")\r\n",
        "plt.ylabel(\"-\")\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmGdoTo4e0rL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}